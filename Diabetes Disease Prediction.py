# -*- coding: utf-8 -*-
"""Proyek Machine Learning - Elisa ramadanti

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lgVUtrol66bSef_IsDzMgAvD3EYcUwFQ

**Laporan Proyek Prediksi Diabetes Menggunakan Machine Learning**

**Nama: Elisa Ramadanti**

# **Domain Proyek**

Diabetes merupakan salah satu penyakit kronis yang banyak diderita masyarakat di seluruh dunia. Menurut [WHO](https://www.who.int/news-room/fact-sheets/detail/diabetes), prevalensi diabetes terus meningkat secara global, menjadikannya masalah kesehatan yang mendesak. Deteksi dini terhadap risiko diabetes sangat penting untuk mencegah komplikasi yang lebih serius, seperti penyakit jantung, stroke, dan kerusakan organ lainnya.

**Prediksi diabetes secara akurat dapat membantu dalam:**
- Deteksi dini risiko diabetes.
- Pencegahan komplikasi yang lebih serius.
- Membantu tenaga medis dalam pengambilan keputusan yang lebih baik.

**Tujuan utama:**  
Mengembangkan model machine learning yang mampu memprediksi risiko diabetes secara akurat berdasarkan data kesehatan individu.

# **Business Understanding**

**Problem Statements**

*   Bagaimana mengidentifikasi individu dengan risiko diabetes menggunakan data kesehatan?
*   Bagaimana meningkatkan akurasi prediksi diabetes menggunakan model machine learning yang tepat?

**Goals**

*  Membuat model machine learning yang mampu memprediksi risiko diabetes dengan akurasi tinggi.
*  Menentukan algoritma terbaik melalui evaluasi model menggunakan beberapa metrik evaluasi.

### **Solution statements**

*  Menggunakan beberapa algoritma klasifikasi, terutama algoritma ensemble seperti **XGBoost**, **LightGBM**, dan **CatBoost**
*  Menerapkan **hyperparameter tuning** menggunakan GridSearchCV untuk mengoptimalkan performa model.

# **Data Understanding**

Dataset yang digunakan adalah **Diabetes Prediction** yang diperoleh dari *Kaggle*. Dataset ini bertujuan untuk memprediksi diabetes berdasarkan faktor risiko yang relevan.

1. **Jumlah Data:**  memiliki **1000 baris dengan 9 Kolom** sebagai berikut:  

2. **Kondisi Data:**
  - Dataset ini memiliki ketidakseimbangan kelas pada kolom Diagnosis, dengan jumlah label "1" (diabetes) dan "0" (tidak diabetes) yang tidak merata. Sehingga Ini perlu diperhatikan untuk menghindari bias pada model prediksi yang akan dibangun.
  - Missing Values: Memeriksa dan memastikan tidak ada nilai yang hilang (missing values).
  - Duplikat: Memeriksa duplikasi dan memastikan tidak ada data yang berulang.
  - Terdapat outlier pada beberapa fitur, yang akan ditangani menggunakan metode IQR.

3. **Sumber Data:** Dataset ini diambil dari [Kaggle - Diabetes Prediction](https://www.kaggle.com/datasets/mrsimple07/diabetes-prediction/data).

4. **Uraian Fitur:**
  - **Pregnancies**: Jumlah kehamilan  
  - **Glucose**: Kadar glukosa dalam darah  
  - **BloodPressure**: Tekanan darah  
  - **SkinThickness**: Ketebalan lipatan kulit  
  - **Insulin**: Kadar insulin  
  - **BMI**: Indeks massa tubuh  
  - **DiabetesPedigreeFunction**: Fungsi silsilah diabetes (mengindikasikan riwayat keluarga)  
  - **Age**: Usia  
  - **Diagnosis**: Label klasifikasi dengan nilai:  
    - **0** = Tidak Diabetes  
    - **1** = Diabetes  
    
5. **Tipe Data:**  
   - Semua fitur numerik memiliki tipe data `float64` atau `int64`.  
   - Tidak ada fitur kategorikal yang memerlukan encoding.

6. **Eksplorasi Data:**  beberapa teknik visualisasi dan analisis eksploratori data akan dilakukan. Misalnya:

  - Distribusi Data: Visualisasi distribusi nilai untuk setiap fitur seperti BMI, Glucose, dan Age untuk memahami sebaran data.
  - Korelasi: Melakukan analisis korelasi antar fitur untuk melihat hubungan yang mungkin ada antar fitur, terutama dengan target label Diagnosis.
  - Imbalance Handling: Menganalisis ketidakseimbangan kelas dalam Diagnosis dan menerapkan teknik seperti SMOTE (Synthetic Minority Over-sampling Technique) untuk menangani masalah tersebut.

## **Import Library**
"""

!pip install catboost

# Import Library
import pandas as pd
import numpy as np
import os
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import ConfusionMatrixDisplay

"""### **Download Dataset**"""

#Dataset ini diambil dari Kaggle menggunakan kode berikut:
import kagglehub

# Download latest version
path = kagglehub.dataset_download("mrsimple07/diabetes-prediction")

print("Path to dataset files:", path)

# Path to the downloaded dataset
path = "/root/.cache/kagglehub/datasets/mrsimple07/diabetes-prediction/versions/1"

# Check the contents of the directory to find the actual filename
print("Files in dataset directory:")
for filename in os.listdir(path):
    print(filename)

"""## **Data Loading**"""

# Load Dataset
filename = 'Diabetes_prediction.csv'
df = pd.read_csv(os.path.join(path, filename))
df.head()

"""## **Assessing Data**

proses ini bertujuan untuk mengidentifikasi masalah yang terdapat dalam data dan memastikan data tersebut berkualitas

**Memeriksa tipe data data dari tiap kolom dengan info()**
"""

df.info()

"""**Insight:**
- **Jumlah Data dan Fitur:** Dataset memiliki 1000 entri dan 9 fitur, cukup untuk klasifikasi dengan machine learning.  
- **Tidak Ada Missing Values:** Semua kolom memiliki 1000 non-null values, tetapi perlu dicek nilai ekstrem yang tidak valid.  
- **Tipe Data:** Terdapat 7 fitur numerik float64 dan 2 fitur int64, sehingga perlu normalisasi atau standardisasi.  
- **Fitur Target (Diagnosis):** Bertipe int64 dan kemungkinan label biner (0 = Tidak Diabetes, 1 = Diabetes). Perlu cek distribusi kelas untuk memastikan data tidak imbalance.

**Menampilkan jumlah missing values yang terdapat dalam setiap kolom data**
"""

df.isnull().sum()

"""**Insight:**

Tidak ditemukan nilai yang hilang pada dataset ini

**Memeriksa duplikasi data**
"""

df.duplicated().sum()

"""**Insight:**

Tidak ditemukan data duplikat pada dataset

**menampilkan ringkasan parameter statistik (mean, median, dll.) dari kolom numerik dengan fungsi describe()**
"""

df.describe()

"""Insigh:

Berdasarkan ringkasan di atas menunjukan bahwa:
- **Pregnancies:** Rata-rata kehamilan adalah 1.77 kali dengan rentang 0 hingga 8. Ini menunjukkan mayoritas responden memiliki sedikit kehamilan.  
- **Glucose:** Rata-rata 99.44 dengan standar deviasi 19.47. Ada nilai minimum 30.57 yang tidak masuk akal, sehingga perlu dicek kemungkinan data error.  
- **BloodPressure:** Rata-rata 72.18, tetapi ada nilai minimum 31.40 yang tidak logis, menunjukkan kemungkinan kesalahan pencatatan atau data kosong yang diisi dengan nol.  
- **SkinThickness:** Distribusi cenderung normal dengan rata-rata 23.28, namun rentang yang sempit (19.37 - 26.92) menunjukkan variabilitas yang rendah.  
- **Insulin:** Rata-rata 84.58 dengan standar deviasi yang tinggi (74.87), dan terdapat nilai negatif (-165.31) yang tidak mungkin. Perlu pembersihan data.  
- **BMI:** Rata-rata 25.43, menunjukkan populasi normal hingga overweight. Namun, nilai minimum 13.54 perlu diperiksa validitasnya.  
- **DiabetesPedigreeFunction:** Rata-rata 0.45 dengan distribusi yang wajar (0.10 - 0.80), menunjukkan faktor genetik dalam risiko diabetes.  
- **Age:** Rata-rata 43.28 tahun dengan rentang -0.98 hingga 90.57. Nilai negatif menunjukkan kesalahan data yang perlu dibersihkan.  
- **Diagnosis:** Kelas target biner dengan rata-rata 0.306, menunjukkan sekitar 30.6% populasi terdiagnosis diabetes, sehingga tidak ada ketidakseimbangan kelas yang ekstrem.

## **Exploratory Data Analysis (EDA)**

Tahap ini akan Mengeksplorasi data dengan menampilkan visualisasi untuk mendapatkan insight yang mudah di pahami, meliputi:

- Distribusi Data: Visualisasi distribusi setiap fitur.
- Korelasi Antar Fitur: Menggunakan heatmap untuk melihat hubungan antar fitur.
- Distribusi Target (Diagnosis): Melihat keseimbangan kelas target.

**Melihat Distribusi Data Diagnosis**
"""

# Distribusi Data pada Kolom Diagnosis
print("\nDistribusi Diagnosis:")
print(df['Diagnosis'].value_counts())

# Visualisasi Distribusi Data Diagnosis
plt.figure(figsize=(6,4))
sns.countplot(x='Diagnosis', data=df)
plt.title('Distribusi Diagnosis')
plt.show()

"""**Insight:**

Terdapat ketidakseimbangan pada distribusi kelas Diagnosis, yang dapat mempengaruhi kinerja model klasifikasi.

**Melihat Rata-rata kolom Berdasarkan Diagnosis Diabetes**
"""

df.groupby('Diagnosis').mean()

"""**Melihat Distribusi Umur Berdasarkan Data Diagnosisi**"""

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='Age', hue='Diagnosis', multiple='stack', bins=20, palette='Blues')
plt.title('Distribusi Umur Berdasarkan Diagnosis')
plt.xlabel('Umur')
plt.ylabel('Jumlah')
plt.legend(title='Diagnosis', labels=['Tidak Diabetes', 'Diabetes'])
plt.show()

"""**Melihat Distribusi Fitur Numerik**"""

# Visualisasi Distribusi Setiap Fitur Numerik
df.hist(bins=30, figsize=(15,10), color='skyblue')
plt.suptitle('Distribusi Fitur Numerik')
plt.show()

"""**Insight:**

Distribusi beberapa fitur menunjukkan adanya outlier dan ketidakwajaran pada nilai minimum.

**Melihat Korelasi Antar Fitur**
"""

# Korelasi Antar Fitur
correlation = df.corr()
print("\nKorelasi Antar Fitur:")
correlation

# Correlation Matrix
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

"""**Visualisasi Hubungan Antar Fitur dengan Pairplot Berdasarkan Diagnosis Diabetes**"""

sns.pairplot(df, hue='Diagnosis')
plt.show()

"""**Visualisasi Distribusi Fitur Berdasarkan Diagnosis Menggunakan Boxplot**"""

for column in df.columns[:-1]:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='Diagnosis', y=column, data=df)
    plt.title(f'Boxplot of {column} by Diagnosis')
    plt.show()

"""**Insight:**

- Boxplot digunakan untuk memvisualisasikan distribusi data fitur numerik berdasarkan kelas target Diagnosis.
- Melalui visualisasi ini, kita dapat mengidentifikasi adanya outlier atau perbedaan distribusi antar kelas (Diabetes vs. Tidak Diabetes) pada setiap fitur.

# **Data Preparation**

### **Data Cleaning**

Pada tahap ini, Membersihkan data dari masalah yang teridentifikasi pada tahap sebelumnya yaitu Outlier. Mengatasi outlier menggunakan metode IQR

### **Mengatasi Outlier**

Outlier pada fitur-fitur data diatasi menggunakan metode IQR untuk meningkatkan akurasi model.
"""

outliers = {}
for col in df.columns:
    if df[col].dtype != 'object':  # Hanya untuk kolom numerik
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
        outliers[col] = outlier_count
print('Jumlah Outlier pada setiap kolom:')
print(outliers)

# Mengatasi Outlier pada Semua Kolom
# Menggunakan metode Z-Score
for col in df.columns:
    if df[col].dtype != 'object':  # Hanya untuk kolom numerik
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        maximum = Q3 + (1.5 * IQR)
        minimum = Q1 - (1.5 * IQR)
        kondisi_lower_than = df[col] < minimum
        kondisi_more_than = df[col] > maximum
        df[col] = df[col].mask(kondisi_more_than, maximum)
        df[col] = df[col].mask(kondisi_lower_than, minimum)
print('Selesai')

outliers = {}
for col in df.columns:
    if df[col].dtype != 'object':  # Hanya untuk kolom numerik
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outlier_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
        outliers[col] = outlier_count
print('Jumlah Outlier pada setiap kolom:')
print(outliers)

"""### **Penanganan Data Tidak Seimbang Menggunakan SMOTE**

**Melihat Distribusi Kelas Sebelum Resampling**
"""

print("\nClass Distribution Before SMOTE:")
print(df['Diagnosis'].value_counts())
sns.countplot(x='Diagnosis', data=df)
plt.show()

"""**Insight:**
-  Terdapat ketidakseimbangan pada distribusi kelas Diagnosis, yang dapat mempengaruhi kinerja model klasifikasi.

### **Menangani Ketidakseimbangan Data dengan SMOTE**

SMOTE (Synthetic Minority Over-sampling Technique) digunakan untuk membuat data sintetis pada kelas minoritas, sehingga distribusi kelas menjadi seimbang.

**Memisahkan Fitur dan Target**
"""

X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']

# Menggunakan SMOTE untuk Oversampling
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

"""**Melihat Distribusi Kelas Setelah SMOTE**"""

print("\nClass Distribution After SMOTE:")
print(np.bincount(y_resampled))
sns.countplot(x=y_resampled)
plt.show()

"""**Insight:**
-  Setelah dilakukan resampling dengan SMOTE, distribusi kelas menjadi seimbang.
-  Hal ini diharapkan dapat meningkatkan performa model klasifikasi, terutama pada kelas yang sebelumnya minoritas.
- Dengan data yang seimbang, model dapat belajar dengan lebih baik dan mengurangi bias terhadap kelas mayoritas
"""

resampled_df = pd.DataFrame(X_resampled, columns=X.columns)
resampled_df['Diagnosis'] = y_resampled
resampled_df

"""### **Data Splitting**

Dataset dibagi menjadi data latih (80%) dan data uji (20%) untuk menguji performa model
"""

# Split Data into Training and Testing Sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

"""### **Feature Scaling**

Menggunakan StandardScaler digunakan untuk menormalkan fitur numerik agar memiliki mean 0 dan standar deviasi 1
"""

# Feature Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#**Modeling**

Pada tahap ini, dilakukan pemodelan menggunakan empat algoritma boosting yang populer: XGBoost, LightGBM, CatBoost, dan Gradient Boosting. Keempat model ini diuji dan dievaluasi menggunakan metrik akurasi, precision, recall, dan F1-score untuk menilai performa dalam memprediksi risiko diabetes.

## **XGBoost**

XGBoost (Extreme Gradient Boosting) adalah algoritma boosting berbasis pohon keputusan yang membangun model secara bertahap. Setiap model baru mencoba memperbaiki kesalahan dari model sebelumnya. XGBoost cenderung memiliki performa yang sangat baik, terutama pada dataset yang kompleks.
"""

# XGBoost Model
xgb_model = XGBClassifier(random_state=42)
xgb_model.fit(X_train, y_train)

y_pred_xgb = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
print('XGBoost Accuracy:', xgb_accuracy)

"""### **Evaluasi Model XGBoost**

**Classification Report XGBoost**
"""

# Classification Report for XGBoost
print("\nClassification Report for XGBoost:")
print(classification_report(y_test, y_pred_xgb))

"""**Insight:**

 XGBoost memberikan akurasi 67.6%, dengan precision yang lebih baik untuk kelas 0 dan recall lebih tinggi untuk kelas 1. Ini menunjukkan model cukup baik dalam menangani risiko diabetes, namun ada ruang untuk perbaikan.

**Confusion Matrix XGBoost**
"""

# Confusion Matrix for XGBoost
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_xgb, cmap='Blues')
plt.title('Confusion Matrix for XGBoost')
plt.show()

"""## **LightGBM**

LightGBM adalah implementasi dari gradient boosting yang dikembangkan oleh Microsoft dan lebih cepat dalam memproses data besar.
"""

# LightGBM Model
lgbm_model = LGBMClassifier(random_state=42)
lgbm_model.fit(X_train, y_train)

y_pred_lgbm = lgbm_model.predict(X_test)
lgbm_accuracy = accuracy_score(y_test, y_pred_lgbm)
print('LightGBM Accuracy:', lgbm_accuracy)

"""### **Evaluasi Model LightGBM**

**Classification Report LightGBM**
"""

# Classification Report for LightGBM
print("\nClassification Report for LightGBM:")
print(classification_report(y_test, y_pred_lgbm))

"""**Insight: **

LightGBM sedikit lebih unggul dibandingkan XGBoost dengan akurasi 68.3%. Precision dan recall hampir seimbang untuk kedua kelas, menunjukkan bahwa model dapat memprediksi dengan cukup baik tanpa terlalu banyak bias terhadap kelas tertentu.
"""

# Confusion Matrix for LightGBM
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lgbm, cmap='Blues')
plt.title('Confusion Matrix for LightGBM')
plt.show()

"""## **CatBoost**

CatBoost adalah algoritma boosting lain yang dirancang untuk menangani data kategorikal tanpa perlu encoding khusus.
"""

catboost_model = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 to suppress logs
catboost_model.fit(X_train, y_train)

y_pred_catboost = catboost_model.predict(X_test)
catboost_accuracy = accuracy_score(y_test, y_pred_catboost)
print("\nCatBoost Accuracy:", catboost_accuracy)

"""### **Evaluasi Model CatBoost**

**Classification Report CatBoost**
"""

print("Classification Report for CatBoost:")
print(classification_report(y_test, y_pred_catboost))

"""**Insight:**

CatBoost menunjukkan performa yang sedikit lebih rendah dibandingkan dengan LightGBM dan XGBoost. Meskipun memiliki precision yang lebih tinggi untuk kelas 0, recall untuk kelas 1 lebih rendah, yang menunjukkan model ini kurang sensitif terhadap risiko diabetes.
"""

# Confusion Matrix for CatBoost
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_catboost, cmap='Blues')
plt.title('Confusion Matrix for CatBoost')
plt.show()

"""# **Hyperparameter Tuning**

Melalui Hyperparameter Tuning, kita dapat meningkatkan performa model dengan memilih kombinasi parameter terbaik metode yang digunakan adalah GridSearchCV, yang memungkinkan pencarian grid atau ruang parameter untuk menemukan kombinasi yang optimal dan meningkatkan akurasi serta performa model secara keseluruhan.

**XGBoost dengan GridSearchCV**

Parameter yang digunakan pada XGBoost meliputi:
"""

# Hyperparameter Tuning for XGBoost
param_grid = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7]
}

grid_search = GridSearchCV(XGBClassifier(random_state=42), param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train, y_train)

best_xgb = grid_search.best_estimator_
y_pred_best_xgb = best_xgb.predict(X_test)
best_xgb_accuracy = accuracy_score(y_test, y_pred_best_xgb)

print("\nBest Parameters for XGBoost:", grid_search.best_params_)
print("Best XGBoost Accuracy:", best_xgb_accuracy)

"""Setelah hyperparameter tuning, parameter terbaik untuk XGBoost adalah learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200

**Evaluasi Model XGBoost dengan GridSearchCV**

Classification Report XGBoost with GridSeachCV
"""

print("\nClassification Report for Best XGBoost Model:")
print(classification_report(y_test, y_pred_best_xgb))

# Confusion Matrix for Best XGBoost Model
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best_xgb, cmap='Blues')
plt.title('Confusion Matrix for Best XGBoost Model')
plt.show()

"""**LightGBM dengan GridSearchCV**"""

lgbm_param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [-1, 5, 10],
    'num_leaves': [31, 50, 100],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0]
}

lgbm_grid_search = GridSearchCV(estimator=lgbm_model,param_grid=lgbm_param_grid,cv=3,scoring='accuracy',n_jobs=-1,verbose=2)

lgbm_grid_search.fit(X_train, y_train)

best_lgbm_model = lgbm_grid_search.best_estimator_
y_pred_best_lgbm = best_lgbm_model.predict(X_test)
best_lgbm_accuracy = accuracy_score(y_test, y_pred_best_lgbm)

print("\nBest Parameters for LightGBM:", lgbm_grid_search.best_params_)
print("Best LightGBM Accuracy:", best_lgbm_accuracy)

"""**Evaluasi Model LightGBM dengan GridSearchCV**

Classification Report LightGBM with GridSeachCV
"""

print("\nClassification Report for Best LightGBM Model:")
print(classification_report(y_test, y_pred_best_lgbm))

# Confusion Matrix for Best LightGBM Model
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best_lgbm, cmap='Blues')
plt.title('Confusion Matrix for Best LightGBM Model')
plt.show()

"""**CatBoost with GridSearchCV**"""

# CatBoost with GridSearchCV
catboost_param_grid = {
    'iterations': [300, 500, 1000],
    'learning_rate': [0.01, 0.1, 0.2],
    'depth': [4, 6, 8],
    'l2_leaf_reg': [1, 3, 5],
    'border_count': [32, 64, 128]
}

catboost_model = CatBoostClassifier(random_state=42, verbose=0)
catboost_grid_search = GridSearchCV(catboost_model, catboost_param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)
catboost_grid_search.fit(X_train, y_train)

best_catboost_model = catboost_grid_search.best_estimator_
y_pred_best_catboost = best_catboost_model.predict(X_test)
best_catboost_accuracy = accuracy_score(y_test, y_pred_best_catboost)

print("\nBest Parameters for CatBoost:", catboost_grid_search.best_params_)
print("Best CatBoost Accuracy:", best_catboost_accuracy)

"""**Evaluasi Model CatBoost with GridSeachCV**

Classification Report CatBoost with GridSeachCV
"""

print("\nClassification Report for Best CatBoost Model:")
print(classification_report(y_test, y_pred_best_catboost))

# Confusion Matrix for Best CatBoost Model
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_best_catboost, cmap='Blues')
plt.title('Confusion Matrix for Best CatBoost Model')
plt.show()

"""**Insight:**

 Hyperparameter tuning membantu meningkatkan performa model secara signifikan, dengan CatBoost mencapai akurasi terbaik di antara semua model.

## **Conclusion**

Berdasarkan hasil evaluasi, CatBoost dengan parameter terbaik setelah hyperparameter tuning memberikan performa terbaik dibandingkan model lainnya. Berikut adalah ringkasan temuan utama dari proyek ini:

**1. Perbandingan Model**

  - CatBoost : Memberikan akurasi tertinggi sebesar 71.6% , diikuti oleh LightGBM dengan akurasi 69.4% dan XGBoost dengan akurasi 65.5% .

**2. Performa Metrik Evaluasi**
  - Precision dan Recall :
    - CatBoost menunjukkan precision yang lebih tinggi untuk kelas 0 (0.74 ) dan recall yang baik untuk kelas 1 (0.77 ), menjadikannya model yang lebih sensitif terhadap risiko diabetes.
    - LightGBM dan XGBoost memiliki precision dan recall yang seimbang untuk kedua kelas, tetapi tidak seoptimal CatBoost.
  - F1-Score :
    - CatBoost mencapai F1-Score tertinggi untuk kedua kelas, yaitu 0.70 (kelas 0) dan 0.73 (kelas 1), yang menunjukkan keseimbangan antara precision dan recall.

**3. Penanganan Ketidakseimbangan Data**
  - Teknik SMOTE berhasil meningkatkan recall untuk kelas minoritas (kelas 1), yang membantu model mengenali lebih banyak kasus diabetes tanpa mengorbankan performa pada kelas mayoritas.
      
**4. Rekomendasi**
  - Model Terbaik : CatBoost adalah pilihan terbaik untuk prediksi risiko diabetes berdasarkan akurasi dan metrik evaluasi lainnya.
  - Hyperparameter Tuning : Langkah ini sangat penting untuk meningkatkan performa model. Parameter terbaik yang diperoleh melalui GridSearchCV secara signifikan meningkatkan akurasi model.

**5. Future Work :**
  - Penambahan Fitur : Menambahkan fitur tambahan seperti riwayat medis keluarga atau gaya hidup dapat meningkatkan akurasi model.
  - Teknik Optimasi Lanjutan : Menggunakan teknik optimasi lain seperti RandomizedSearchCV atau Bayesian Optimization untuk eksplorasi ruang parameter yang lebih luas.
  - Algoritma Alternatif : Menguji algoritma lain seperti Random Forest atau Neural Networks untuk memverifikasi apakah ada model yang lebih baik.
"""